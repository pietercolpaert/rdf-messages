<pre class='metadata'>
Title: RDF Messages
Shortname: RDF-M
Level: 1
Status: LD
Markup Shorthands: markdown yes
URL: https://www.pieter.pm/rdf-messages
Editor: Pieter Colpaert, https://pietercolpaert.be
Repository: https://github.com/pietercolpaert/rdf-messages
Abstract: Concepts and abstract data model for RDF Messages
</pre>

# Introduction # {#introduction}

An <dfn>RDF Message</dfn> is an [RDF Dataset](https://www.w3.org/TR/rdf12-concepts/#dfn-rdf-dataset) that is intended to be interpreted atomically as a single communicative act.

Note: While no formal restrictions on the size of an RDF Message is defined, they are intended to be kept rather small and actionable.

<figure>
<div class="example" highlight="turtle">
```turtle
PREFIX as: <https://www.w3.org/ns/activitystreams#>
PREFIX ex: <http://example.org/>

ex:like-1 a as:Like ;
  as:object ex:blogpost-1 ;
  as:actor <https://pietercolpaert.be/#me> .
```
</div>
<figcaption>Example of a message using the [[!activitystreams-vocabulary]] vocabulary.</figcaption>
</figure>

Note: You cannot refer to a specific RDF Message, you can only understand the quads belong together. You can however refer to resources defined within the message, such as to `ex:like-1` in the example above.

An <dfn>RDF Message Stream</dfn> carries [=RDF Messages=] from one specific producer to one specific consumer.

Note: This is concept is different from an RDF quad stream that carries individual quads.

A <dfn>stream consumer</dfn> listens in on the stream using a stream protocol.

A <dfn>stream producer</dfn> makes available a stream using a stream protocol.

An <dfn>RDF Message Log</dfn> is an ordered collection of [=RDF Messages=].
The log can be serialized from an [=RDF Message Stream=], and/or deserialized into an [=RDF Message Stream=].

<figure>
<div class="example" highlight="turtle">
```turtle
# --- a message defining the context
ex:Stream1 a ex:Dataset;
    rdfs:comment "A log of messages that appeared on a stream" .
# --- a next message is an observation in the stream
ex:Observation1
    a sosa:Observation ;
	sosa:resultTime "2026-01-01T00:00:00Z"^^xsd:dateTime ;
	sosa:hasSimpleResult "..." .
# --- another observation
ex:Observation2
    a sosa:Observation ;
	sosa:resultTime "2026-01-01T00:10:00Z"^^xsd:dateTime ;
	sosa:hasSimpleResult "..." .
	
```
</div>
<figcaption>Example of an [=RDF Message Log=] publishing the [=RDF Messages=] that appeared in a stream so far.</figcaption>
</figure>

Note: A producer may want to indicate that a certain property is used to indicate the timestamp of when the message was created. This can be done, for example, using `ldes:timestampPath` from [Linked Data Event Streams](https://w3id.org/ldes/specification). Alternatively, when vocabularies such as ActivityStreams, SSN/SOSA, or PROV-O are used, one can just assume the respective properties `as:published`, `sosa:resultTime`, or `prov:generatedAtTime` are going to be used for this purpose.

Note: The scope of blank nodes is defined by the underlying protocol. E.g. for documents with multiple RDF messages in them, this remains the document itself.

# RDF Message Streams # {#rdf-message-streams}

A [=stream consumer=] has functionality to create and access a new [=RDF Message Stream=]. A stream instance thus only exists when it is being consumed.

A function is called on the [=stream consumer=], as specified by the underlying protocol, when the [=stream producer=] sends a new [=RDF Message=] on the [=RDF Message Stream=].

Note: This is an abstraction over protocols and APIs such as [[!WebSockets]], C-SPARQL, SPARQL-ES, [gRPC](https://grpc.io/), [[!LDN]], [[!EventSource]], [Linked Data Event Streams](https://w3id.org/ldes/specification), [Jelly](https://w3id.org/jelly/), [MQTT](https://mqtt.org/), or programming language-specific stream interface that carries RDF Datasets, or a collection or stream of RDF Quads.

A [=stream producer=] MAY provide a mechanism to write only when a [=stream consumer=] is ready to process the next message.

Issue: Find out and document the similarities/differences to the [RDF-JS Stream interface](https://rdf.js.org/stream-spec/)

# RDF Message Logs # {#rdf-message-logs}

In this specification we propose that all RDF serializations MUST implement a way to group quads into [=RDF Messages=].
This way, a [=stream consumer=] can write the stream into an [=RDF Message Log=] that can be read again by a [=stream producer=] into an [=RDF Message Stream=].

The RDF serializations are either way being revised in the upcoming RDF1.2 specification, in which [version labels](https://www.w3.org/TR/rdf12-concepts/#defined-version-labels) are proposed. We could ask to the working group to include this concept by including yet another `content-type` directive as follows: `Content-Type: application/trig; version=1.2; messages=tdc`. This indicates that a triple dash comment (tdc) in this HTTP Response indicates the start of a new RDF Message. Clients that do not rely on [=RDF Messages=] can still interpret the response as regular RDF1.2 data.

TODO: For JSON-LD and RDF/XML?

## Example: an archive of an RDF Stream ## {#stream-archive}

When you write out an [=RDF Message Log=] into a file, all [=RDF Messages=] are preserved when deserializing it again.
This can be streamed out in the same order as it was written into the file as well.

Without the semantics of an [=RDF Message=], and without the syntax for it, trying to reconstruct the intended message becomes slow and cannot be solved without using sub-optimal heuristics.
The performance loss is due to the fact that there could always be another quad at the end of the file that still needs to be considered for the message, as you cannot rely on the quads being grouped together.
A heuristic is needed as you can only guess that e.g. subject-based star patterns, or maybe a [[!CBD]], or maybe a named graph is going to be used.
This is what is being used by [the Linked Data Event Streams “member extraction” step](https://semiceu.github.io/LinkedDataEventStreams/#members).

## Example: SPARQL CONSTRUCT results ## {#sparql-construct-messages}

<figure>
<div class="example" highlight="sparql">
```sparql
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX dbo: <http://dbpedia.org/ontology/>
PREFIX dbp: <http://dbpedia.org/property/>
CONSTRUCT {
  ?company a dbo:Company ;
       dbo:location ?location .
  
  ?location rdf:type dbo:Country ;
            rdfs:label ?lname ;
            dbp:populationCensus ?pop .
} WHERE {
    ?company dbo:location | dbo:locationCountry ?location .
    
    ?location rdf:type dbo:Country ;
              rdfs:label ?lname ;
              dbp:populationCensus | dbo:populationTotal ?pop .
    
    FILTER (LANG(?lname) = "en")
} ORDER BY ?location LIMIT 10000
```
</div>
<figcaption>If the query engine would support RDF message logs to indicate that groups of triples are part of a certain result, it would speed up clients that want to use the message as a meaningful concept. <a href="https://dbpedia.org/sparql?default-graph-uri=http%3A%2F%2Fdbpedia.org&query=PREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0D%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0D%0APREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0D%0APREFIX+dbp%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fproperty%2F%3E%0D%0ACONSTRUCT+%7B%0D%0A++%3Fcompany+a+dbo%3ACompany+%3B%0D%0A+++++++dbo%3Alocation+%3Flocation+.%0D%0A++%0D%0A++%3Flocation+rdf%3Atype+dbo%3ACountry+%3B%0D%0A++++++++++++rdfs%3Alabel+%3Flname+%3B%0D%0A++++++++++++dbp%3ApopulationCensus+%3Fpop+.%0D%0A%7D+WHERE+%7B%0D%0A++++%3Fcompany+dbo%3Alocation+%7C+dbo%3AlocationCountry+%3Flocation+.%0D%0A++++%0D%0A++++%3Flocation+rdf%3Atype+dbo%3ACountry+%3B%0D%0A++++++++++++++rdfs%3Alabel+%3Flname+%3B%0D%0A++++++++++++++dbp%3ApopulationCensus+%7C+dbo%3ApopulationTotal+%3Fpop+.%0D%0A++++FILTER+%28LANG%28%3Flname%29+%3D+%22en%22%29%0D%0A%7D+ORDER+BY+%3Flocation+LIMIT+1000+&format=text%2Fturtle&timeout=30000&signal_void=on&signal_unconnected=on">Test query in dbpedia</a>&mdash;<a href="https://query.linkeddatafragments.org/#transientDatasources=%2F%2Ffragments.dbpedia.org%2F2016-04%2Fen&query=PREFIX%20rdf%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0APREFIX%20rdfs%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX%20dbo%3A%20%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX%20dbp%3A%20%3Chttp%3A%2F%2Fdbpedia.org%2Fproperty%2F%3E%0ACONSTRUCT%20%7B%0A%20%20%3Fcompany%20a%20dbo%3ACompany%20%3B%0A%20%20%20%20%20%20%20dbo%3Alocation%20%3Flocation%20.%0A%20%20%0A%20%20%3Flocation%20rdf%3Atype%20dbo%3ACountry%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3Flname%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20dbp%3ApopulationCensus%20%3Fpop%20.%0A%7D%20WHERE%20%7B%0A%20%20%20%20%3Fcompany%20dbo%3Alocation%20%7C%20dbo%3AlocationCountry%20%3Flocation%20.%0A%20%20%20%20%0A%20%20%20%20%3Flocation%20rdf%3Atype%20dbo%3ACountry%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3Flname%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20dbp%3ApopulationCensus%20%7C%20dbo%3ApopulationTotal%20%3Fpop%20.%0A%20%20%20%20FILTER%20%28LANG%28%3Flname%29%20%3D%20%22en%22%29%0A%7D%20LIMIT%201000%20">Test using Comunica</a></figcaption>
</figure>

The example generates 10000 companies in countries and lists the population number of the country.
Now imagine that a consumer wants to process the results of this SPARQL query, where each construct result is an [=RDF Message=].
While the server could have grouped the quads for the consumer, the consumer will have to re-construct the BGP in the CONSTRUCT clause again on the client before it can proceed.
The obvious solution here is to use an [=RDF Message Stream=].

