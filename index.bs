<pre class='metadata'>
Title: RDF Messages
Shortname: RDF-M
Level: 1
Status: LD
Markup Shorthands: markdown yes
URL: https://www.pieter.pm/rdf-messages
Editor: Pieter Colpaert, https://pietercolpaert.be
Editor: Piotr Sowiński, https://ostrzyciel.eu/
Repository: https://github.com/pietercolpaert/rdf-messages
Abstract: Concepts and abstract data model for RDF Messages
</pre>

# Introduction # {#introduction}

An <dfn>RDF Message</dfn> is an [RDF Dataset](https://www.w3.org/TR/rdf12-concepts/#dfn-rdf-dataset) that is intended to be interpreted atomically as a single communicative act.

Note: While no formal restrictions on the size of an RDF Message is defined, they are intended to be kept rather small and actionable.

<figure>
<div class="example" highlight="turtle">
```turtle
PREFIX as: <https://www.w3.org/ns/activitystreams#>
PREFIX ex: <http://example.org/>

ex:like-1 a as:Like ;
  as:object ex:blogpost-1 ;
  as:actor <https://pietercolpaert.be/#me> .
```
</div>
<figcaption>Example of a message using the [[!activitystreams-vocabulary]] vocabulary.</figcaption>
</figure>

Note: You cannot refer to a specific RDF Message, you can only understand the quads belong together. You can however refer to resources defined within the message, such as to `ex:like-1` in the example above.

An <dfn>RDF Message Stream</dfn> instance carries [=RDF Messages=] from one specific producer to one specific consumer.

Note: This is concept is different from an RDF quad stream that carries individual quads.

A <dfn>stream consumer</dfn> listens in on the stream using a stream protocol.

A <dfn>stream producer</dfn> makes available a stream using a stream protocol.

Note: The underlying stream protocol is out of scope of this specification. It can be for example [[!WebSockets]], [[!LDN]], [[!EventSource]], [Linked Data Event Streams](https://w3id.org/ldes/specification), [Jelly gRPC](https://w3id.org/jelly/), [MQTT](https://mqtt.org/), or a programming language-specific stream interface that carries RDF Datasets, or a collection or stream of RDF Quads.

An <dfn>RDF Message Log</dfn> is an ordered collection of [=RDF Messages=].
The log can be serialized from an [=RDF Message Stream=], and/or deserialized into an [=RDF Message Stream=].

<figure>
<div class="example" highlight="turtle">
```turtle
# a message defining the context
ex:Stream1 a ex:Dataset;
    rdfs:comment "A log of messages that appeared on a stream" .
# @message a next message is an observation in the stream
ex:Observation1
    a sosa:Observation ;
    sosa:resultTime "2026-01-01T00:00:00Z"^^xsd:dateTime ;
    sosa:hasSimpleResult "..." .
# @message another observation
ex:Observation2
    a sosa:Observation ;
    sosa:resultTime "2026-01-01T00:10:00Z"^^xsd:dateTime ;
    sosa:hasSimpleResult "..." .	
```
</div>
<figcaption>Example of an [=RDF Message Log=] publishing the [=RDF Messages=] that appeared in a stream so far.</figcaption>
</figure>

Note: A producer may want to indicate that a certain property is used to indicate the timestamp of when the message was created. This can be done, for example, using `ldes:timestampPath` from [Linked Data Event Streams](https://w3id.org/ldes/specification). Alternatively, when vocabularies such as ActivityStreams, SSN/SOSA, or PROV-O are used, one can just assume the respective properties `as:published`, `sosa:resultTime`, or `prov:generatedAtTime` are going to be used for this purpose.

Note: The scope of blank nodes is defined by the underlying protocol. E.g. for documents with multiple RDF messages in them, this remains the document itself.

Issue: If blank nodes in an N-Quads Message Log are scoped to the entire document, then to serialize a long stream and avoid blank node collisions, the producer would need to store in memory all blank nodes ever used or rely on UUIDs. Is this feasible? See also: [Issue #3](https://github.com/pietercolpaert/rdf-messages/issues/3)

# RDF Message Streams # {#rdf-message-streams}

A [=stream consumer=] has functionality to create and access a new [=RDF Message Stream=] instance. An instance thus only exists when it is being consumed.

A function is called on the [=stream consumer=], as specified by the underlying protocol, when the [=stream producer=] sends a new [=RDF Message=] on the [=RDF Message Stream=].

Note: This is an abstraction over the underlying protocol or API.

A [=stream producer=] MAY provide a mechanism to write only when a [=stream consumer=] is ready to process the next message.

Issue: Find out and document the similarities/differences to the [RDF-JS Stream interface](https://rdf.js.org/stream-spec/)

# Serializing RDF Message Logs # {#rdf-message-logs}

In this specification we propose that all RDF serializations MUST implement a way to group quads into [=RDF Messages=].
This way, a [=stream consumer=] can write the stream into an [=RDF Message Log=] that can be read again by a [=stream producer=] into an [=RDF Message Stream=].

## From N-Triples and Turtle to TRiG ## {#turtle}

The RDF serializations are either way being revised in the upcoming RDF1.2 specification, in which [version labels](https://www.w3.org/TR/rdf12-concepts/#defined-version-labels) are proposed.
This is a proposal to the working group to include this concept by including yet another `content-type` directive as follows: `Content-Type: application/trig; version=1.2; messages=rdfm`.
This indicates that the messages are following this spec in this HTTP Response. Clients that do not rely on [=RDF Messages=] can still interpret the response as regular RDF1.2 data.

When the `content-type` flagged the support for messages, and a parser is in message mode, it MUST:
 1. Consider every triple in the document as part of an [=RDF Message=]. The document thus does not need to start with a delimited.
 2. Triples are added to the current message as long as no delimiter or EOF has been encountered.
 3. When a delimiter was encountered, the current [=RDF Message=] is finalized and a next one is opened.

The delimiter is a comment in the document that matches this regex: `/^\s*@message/`.

## JSON-LD ## {#json-ld}

Issue: This discussion is preliminary, yet on-going, in the JSON-LD group itself with a proposal called [newline delimited JSON-LD](https://github.com/json-ld/ndjson-ld/issues/1). We propose that that specification becomes the preferred way of adding messages support in JSON-LD.

## RDF/XML ## {#rdf-xml}

Each message is a new XML document on a new line.

This is made discoverable with a new content-type: `Content-Type: application/rdfm+xml`

# Examples and use cases # {#examples}

## An archive of an RDF Stream ## {#stream-archive}

When you write out an [=RDF Message Log=] into a file, all [=RDF Messages=] are preserved when deserializing it again.
They are streamed out in the same order as they were written into the file.

Without the semantics of an [=RDF Message=], and without the syntax for it, trying to reconstruct the intended message becomes slow and cannot be solved without using sub-optimal heuristics.
The performance loss is due to the fact that there could always be another quad at the end of the file that still needs to be considered for the message, as you cannot rely on the quads being grouped together.
A heuristic is needed as you can only guess that e.g. subject-based star patterns, or maybe a [[!CBD]], or maybe a named graph is going to be used.
This is what is being used by [the Linked Data Event Streams “member extraction” step](https://semiceu.github.io/LinkedDataEventStreams/#members).

## SPARQL CONSTRUCT results ## {#sparql-construct-messages}

<figure>
<div class="example" highlight="sparql">
```sparql
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX dbo: <http://dbpedia.org/ontology/>
PREFIX dbp: <http://dbpedia.org/property/>
CONSTRUCT {
  ?company a dbo:Company ;
       dbo:location ?location .
  
  ?location rdf:type dbo:Country ;
            rdfs:label ?lname ;
            dbp:populationCensus ?pop .
} WHERE {
    ?company dbo:location | dbo:locationCountry ?location .
    
    ?location rdf:type dbo:Country ;
              rdfs:label ?lname ;
              dbp:populationCensus | dbo:populationTotal ?pop .
    
    FILTER (LANG(?lname) = "en")
} ORDER BY ?location LIMIT 10000
```
</div>
<figcaption>If the query engine would support RDF message logs to indicate that groups of triples are part of a certain result, it would speed up clients that want to use the message as a meaningful concept.</figcaption>
</figure>

The example (Test it using the [DBpedia SPARQL endpoint](https://dbpedia.org/sparql?default-graph-uri=http%3A%2F%2Fdbpedia.org&query=PREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0D%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0D%0APREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0D%0APREFIX+dbp%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fproperty%2F%3E%0D%0ACONSTRUCT+%7B%0D%0A++%3Fcompany+a+dbo%3ACompany+%3B%0D%0A+++++++dbo%3Alocation+%3Flocation+.%0D%0A++%0D%0A++%3Flocation+rdf%3Atype+dbo%3ACountry+%3B%0D%0A++++++++++++rdfs%3Alabel+%3Flname+%3B%0D%0A++++++++++++dbp%3ApopulationCensus+%3Fpop+.%0D%0A%7D+WHERE+%7B%0D%0A++++%3Fcompany+dbo%3Alocation+%7C+dbo%3AlocationCountry+%3Flocation+.%0D%0A++++%0D%0A++++%3Flocation+rdf%3Atype+dbo%3ACountry+%3B%0D%0A++++++++++++++rdfs%3Alabel+%3Flname+%3B%0D%0A++++++++++++++dbp%3ApopulationCensus+%7C+dbo%3ApopulationTotal+%3Fpop+.%0D%0A++++FILTER+%28LANG%28%3Flname%29+%3D+%22en%22%29%0D%0A%7D+ORDER+BY+%3Flocation+LIMIT+1000+&format=text%2Fturtle&timeout=30000&signal_void=on&signal_unconnected=on) or [using Comunica](https://query.linkeddatafragments.org/#transientDatasources=%2F%2Ffragments.dbpedia.org%2F2016-04%2Fen&query=PREFIX%20rdf%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0APREFIX%20rdfs%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX%20dbo%3A%20%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX%20dbp%3A%20%3Chttp%3A%2F%2Fdbpedia.org%2Fproperty%2F%3E%0ACONSTRUCT%20%7B%0A%20%20%3Fcompany%20a%20dbo%3ACompany%20%3B%0A%20%20%20%20%20%20%20dbo%3Alocation%20%3Flocation%20.%0A%20%20%0A%20%20%3Flocation%20rdf%3Atype%20dbo%3ACountry%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3Flname%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20dbp%3ApopulationCensus%20%3Fpop%20.%0A%7D%20WHERE%20%7B%0A%20%20%20%20%3Fcompany%20dbo%3Alocation%20%7C%20dbo%3AlocationCountry%20%3Flocation%20.%0A%20%20%20%20%0A%20%20%20%20%3Flocation%20rdf%3Atype%20dbo%3ACountry%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3Flname%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20dbp%3ApopulationCensus%20%7C%20dbo%3ApopulationTotal%20%3Fpop%20.%0A%20%20%20%20FILTER%20%28LANG%28%3Flname%29%20%3D%20%22en%22%29%0A%7D%20LIMIT%201000%20)) generates 10000 companies in countries and lists the population number of the country.
Now imagine that a consumer wants to process the results of this SPARQL query, where each construct result is an [=RDF Message=].
While the server could have grouped the quads for the consumer, the consumer will have to re-construct the BGP in the CONSTRUCT clause again on the client before it can proceed.
The obvious solution here is to use an [=RDF Message Stream=].

## RiverBench dataset distributions ## {#riverbench-dataset-distributions}

Datasets in [RiverBench](https://w3id.org/riverbench/) are streams of RDF datasets that can be processed individually as RDF Messages. They represent real-world use cases of streaming RDF data.
For example, the [officegraph dataset](https://w3id.org/riverbench/datasets/officegraph/dev) consists of almost 15 million RDF graphs with IoT measurements (see example below).

<figure>
<div class="example" highlight="turtle">
```turtle
PREFIX ic:    <https://interconnectproject.eu/example/>
PREFIX om:    <http://www.wurvoc.org/vocabularies/om-1.8/>
PREFIX saref: <https://saref.etsi.org/core/>
PREFIX xsd:   <http://www.w3.org/2001/XMLSchema#>

ic:property_R5_56__co2_
        a       ic:CO2Level .

ic:measurement_R5_56__co2__0
        a                        saref:Measurement;
        saref:hasTimestamp       "2022-02-28T23:59:00"^^xsd:dateTime;
        saref:hasValue           "504"^^xsd:float;
        saref:isMeasuredIn       om:partsPerMillion;
        saref:relatesToProperty  ic:property_R5_56__co2_ .
```
</div>
<figcaption>Example of an RDF Message in the officegraph dataset.</figcaption>
</figure>

To distribute this stream, a TAR archive is used, where each file in the archive is an RDF Message in the stream.
This could be greatly improved by using an [=RDF Message Log=] serialization instead, as this would allow to save the entire stream into a single file, while still being able to reconstruct the individual messages again.
